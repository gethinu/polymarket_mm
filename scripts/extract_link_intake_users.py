#!/usr/bin/env python3
"""
Extract wallet/profile user seeds from link-intake JSON (observe-only).

Examples:
  python scripts/extract_link_intake_users.py logs/link_intake_20260224_7links.json
  python scripts/extract_link_intake_users.py logs/link_intake_20260224_7links.json --resolve-profiles
"""

from __future__ import annotations

import argparse
import datetime as dt
import json
import re
from pathlib import Path
from typing import Dict, List, Optional, Sequence, Tuple
from urllib.parse import unquote, urlparse

from fetch_trades import resolve_user_identifier


CONFIDENCE_RANK: Dict[str, int] = {
    "none": 0,
    "low": 1,
    "medium": 2,
    "high": 3,
}

HANDLE_RE = re.compile(r"^[A-Za-z0-9_-]{1,128}$")
WALLET_RE = re.compile(r"0x[a-fA-F0-9]{40}")


def now_utc() -> dt.datetime:
    return dt.datetime.now(dt.timezone.utc)


def repo_root() -> Path:
    return Path(__file__).resolve().parents[1]


def confidence_rank(label: str) -> int:
    return CONFIDENCE_RANK.get((label or "").strip().lower(), 0)


def normalize_handle(raw: str) -> Optional[str]:
    handle = (raw or "").strip()
    if handle.startswith("@"):
        handle = handle[1:]
    if not HANDLE_RE.match(handle):
        return None
    return handle


def canonical_profile_url(handle: str) -> str:
    return f"https://polymarket.com/@{handle}"


def extract_profile_handle_from_url(url: str) -> Optional[str]:
    raw = (url or "").strip()
    if not raw:
        return None
    if raw.startswith("polymarket.com/"):
        raw = f"https://{raw}"
    if not (raw.startswith("http://") or raw.startswith("https://")):
        return None

    try:
        parsed = urlparse(raw)
    except Exception:
        return None

    host = (parsed.netloc or "").lower()
    if host.startswith("www."):
        host = host[4:]
    if host != "polymarket.com":
        return None

    path = unquote(parsed.path or "").strip("/")
    if not path:
        return None
    parts = [p for p in path.split("/") if p]
    if not parts:
        return None

    for part in parts:
        if part.startswith("@") and len(part) > 1:
            return normalize_handle(part[1:])

    if "profile" in parts:
        i = parts.index("profile")
        if i + 1 < len(parts):
            nxt = parts[i + 1]
            if nxt.startswith("@") and len(nxt) > 1:
                return normalize_handle(nxt[1:])
            return normalize_handle(nxt)
    return None


def extract_profile_handles_from_text(text: str) -> List[str]:
    found: List[str] = []
    seen = set()
    patterns = [
        r"(?:https?://)?(?:www\.)?polymarket\.com/(?:en/)?@([A-Za-z0-9_-]{1,128})",
        r"(?:https?://)?(?:www\.)?polymarket\.com/(?:en/)?profile/(?:%40|@)([A-Za-z0-9_-]{1,128})",
    ]
    for pat in patterns:
        for m in re.findall(pat, text or "", flags=re.IGNORECASE):
            handle = normalize_handle(str(m))
            if not handle:
                continue
            key = handle.lower()
            if key in seen:
                continue
            seen.add(key)
            found.append(handle)
    return found


def extract_wallets(text: str) -> List[str]:
    out: List[str] = []
    seen = set()
    for m in WALLET_RE.findall(text or ""):
        w = str(m).lower()
        if w in seen:
            continue
        seen.add(w)
        out.append(w)
    return out


def resolve_path(raw_path: str, default_name: str) -> Path:
    logs = repo_root() / "logs"
    logs.mkdir(parents=True, exist_ok=True)
    if not raw_path:
        return logs / default_name
    p = Path(raw_path)
    if p.is_absolute():
        return p
    if len(p.parts) == 1:
        return logs / p.name
    return repo_root() / p


def load_text_if_exists(path_str: str) -> str:
    if not path_str:
        return ""
    p = Path(path_str)
    if not p.is_absolute():
        p = repo_root() / p
    try:
        return p.read_text(encoding="utf-8", errors="replace")
    except Exception:
        return ""


def dedup_preserve(values: Sequence[str]) -> List[str]:
    out: List[str] = []
    seen = set()
    for v in values:
        key = (v or "").strip().lower()
        if not key:
            continue
        if key in seen:
            continue
        seen.add(key)
        out.append(v.strip())
    return out


def main() -> int:
    p = argparse.ArgumentParser(description="Extract wallet/profile seed users from link-intake JSON")
    p.add_argument("intake_json", help="Input JSON generated by link-intake tooling")
    p.add_argument(
        "--min-confidence",
        default="low",
        choices=["none", "low", "medium", "high"],
        help="Minimum confidence row level to include",
    )
    p.add_argument(
        "--resolve-profiles",
        action="store_true",
        help="Resolve extracted profile URLs/handles to wallets (observe-only network calls)",
    )
    p.add_argument("--out-user-file", default="", help="Output newline-separated user seed file")
    p.add_argument("--out-json", default="", help="Output extraction summary JSON path")
    p.add_argument("--pretty", action="store_true", help="Pretty-print output JSON")
    args = p.parse_args()

    intake_path = Path(args.intake_json)
    if not intake_path.is_absolute():
        intake_path = repo_root() / intake_path
    if not intake_path.exists():
        print(f"Input JSON not found: {intake_path}")
        return 2

    try:
        payload = json.loads(intake_path.read_text(encoding="utf-8"))
    except Exception as e:
        print(f"Failed to read JSON: {e}")
        return 2

    rows = payload.get("rows") if isinstance(payload.get("rows"), list) else []
    min_rank = confidence_rank(args.min_confidence)

    row_summaries: List[dict] = []
    profile_index: Dict[str, dict] = {}
    wallet_index: Dict[str, dict] = {}

    for i, row in enumerate(rows, start=1):
        index = int(row.get("index") or i)
        source_url = str(row.get("source_url") or "").strip()
        confidence = str(row.get("confidence") or "").strip().lower()
        ok = bool(row.get("ok"))
        include = ok and confidence_rank(confidence) >= min_rank

        referenced_urls = row.get("referenced_urls") if isinstance(row.get("referenced_urls"), list) else []
        raw_text = load_text_if_exists(str(row.get("output_file") or ""))

        row_handles: List[str] = []
        row_handles_from_urls: List[str] = []
        row_wallets: List[str] = []

        if include:
            url_candidates: List[str] = []
            if source_url:
                url_candidates.append(source_url)
            for u in referenced_urls:
                s = str(u or "").strip()
                if s:
                    url_candidates.append(s)

            for u in url_candidates:
                h = extract_profile_handle_from_url(u)
                if h:
                    row_handles_from_urls.append(h)
                    row_handles.append(h)

            row_handles.extend(extract_profile_handles_from_text(raw_text))

            wallet_scan_text = "\n".join(url_candidates) + "\n" + raw_text
            row_wallets.extend(extract_wallets(wallet_scan_text))

        row_handles = dedup_preserve(row_handles)
        row_wallets = dedup_preserve(row_wallets)

        for h in row_handles:
            key = h.lower()
            if key not in profile_index:
                profile_index[key] = {
                    "handle": h,
                    "profile_url": canonical_profile_url(h),
                    "first_seen_row": index,
                    "first_seen_source_url": source_url,
                    "seen_in_url": h in row_handles_from_urls,
                }
            else:
                profile_index[key]["seen_in_url"] = bool(profile_index[key].get("seen_in_url")) or (h in row_handles_from_urls)

        for w in row_wallets:
            key = w.lower()
            if key not in wallet_index:
                wallet_index[key] = {
                    "wallet": w,
                    "first_seen_row": index,
                    "first_seen_source_url": source_url,
                    "source": "text_extract",
                }

        row_summaries.append(
            {
                "index": index,
                "source_url": source_url,
                "ok": ok,
                "confidence": confidence,
                "included": include,
                "profiles": [canonical_profile_url(x) for x in row_handles],
                "wallets": row_wallets,
                "gaps": row.get("gaps") if isinstance(row.get("gaps"), list) else [],
                "output_file": str(row.get("output_file") or ""),
            }
        )

    if args.resolve_profiles:
        for key in sorted(profile_index.keys(), key=lambda x: (profile_index[x]["first_seen_row"], x)):
            info = profile_index[key]
            profile_url = str(info.get("profile_url") or "")
            wallet, meta = resolve_user_identifier(profile_url)
            info["resolved_wallet"] = wallet or ""
            info["resolved_via"] = str(meta.get("resolved_via") or "")
            if wallet:
                wkey = wallet.lower()
                if wkey not in wallet_index:
                    wallet_index[wkey] = {
                        "wallet": wallet,
                        "first_seen_row": info.get("first_seen_row"),
                        "first_seen_source_url": info.get("first_seen_source_url"),
                        "source": "profile_resolve",
                    }

    ordered_profiles = sorted(
        profile_index.values(),
        key=lambda x: (int(x.get("first_seen_row") or 0), str(x.get("profile_url") or "").lower()),
    )
    ordered_wallets = sorted(
        wallet_index.values(),
        key=lambda x: (int(x.get("first_seen_row") or 0), str(x.get("wallet") or "").lower()),
    )

    users: List[str] = []
    seen_users = set()

    # Build user-file candidates in row order for stable downstream behavior.
    profile_lookup = {str(x.get("profile_url") or "").lower(): x for x in ordered_profiles}
    for row in row_summaries:
        if not row.get("included"):
            continue
        profile_urls = row.get("profiles") if isinstance(row.get("profiles"), list) else []
        wallets = row.get("wallets") if isinstance(row.get("wallets"), list) else []

        for purl in profile_urls:
            candidate = str(purl)
            if args.resolve_profiles:
                info = profile_lookup.get(candidate.lower())
                resolved_wallet = str((info or {}).get("resolved_wallet") or "")
                if resolved_wallet:
                    candidate = resolved_wallet
                elif not bool((info or {}).get("seen_in_url")):
                    # Drop unresolved text-only handles (often truncated in social excerpts).
                    continue
            key = candidate.lower()
            if key in seen_users:
                continue
            seen_users.add(key)
            users.append(candidate)

        for wallet in wallets:
            candidate = str(wallet).lower()
            key = candidate.lower()
            if key in seen_users:
                continue
            seen_users.add(key)
            users.append(candidate)

    out_user_file = resolve_path(args.out_user_file, "link_intake_users_latest.txt")
    out_json = resolve_path(args.out_json, "link_intake_users_latest.json")
    out_user_file.parent.mkdir(parents=True, exist_ok=True)
    out_json.parent.mkdir(parents=True, exist_ok=True)

    if users:
        out_user_file.write_text("\n".join(users) + "\n", encoding="utf-8")
    else:
        out_user_file.write_text("", encoding="utf-8")

    out_payload = {
        "meta": {
            "generated_at_utc": now_utc().isoformat(),
            "tool": "extract_link_intake_users.py",
            "input_json": str(intake_path),
            "min_confidence": args.min_confidence,
            "resolve_profiles": bool(args.resolve_profiles),
            "row_count_total": len(rows),
            "row_count_included": sum(1 for r in row_summaries if r.get("included")),
            "profile_count": len(ordered_profiles),
            "wallet_count": len(ordered_wallets),
            "user_count": len(users),
            "out_user_file": str(out_user_file),
        },
        "users": users,
        "profiles": ordered_profiles,
        "wallets": ordered_wallets,
        "rows": row_summaries,
    }

    with out_json.open("w", encoding="utf-8") as f:
        if args.pretty:
            json.dump(out_payload, f, indent=2, ensure_ascii=False)
        else:
            json.dump(out_payload, f, separators=(",", ":"), ensure_ascii=False)

    print(f"Input rows: {len(rows)}")
    print(f"Included rows: {sum(1 for r in row_summaries if r.get('included'))}")
    print(f"Profiles extracted: {len(ordered_profiles)}")
    print(f"Wallets extracted: {len(ordered_wallets)}")
    print(f"User seeds: {len(users)}")
    print(f"Saved user file: {out_user_file}")
    print(f"Saved summary JSON: {out_json}")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
